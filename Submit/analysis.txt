Flat profile:

Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total           
 time   seconds   seconds    calls   s/call   s/call  name    
100.00      1.56     1.56        1     1.56     1.56  wakeup_delay()
  0.00      1.56     0.00       23     0.00     0.00  interval(timespec, timespec)
  0.00      1.56     0.00       11     0.00     0.00  gpuAssert(cudaError, char*, int, bool)
  0.00      1.56     0.00        1     0.00     0.00  cuda_conv_1D_tiled_and_shared_memory_kernel2(float*, float*, int, int)
  0.00      1.56     0.00        1     0.00     0.00  __device_stub__Z44cuda_conv_1D_tiled_and_shared_memory_kernel2PfS_ii(float*, float*, int, int)
  0.00      1.56     0.00        1     0.00     0.00  conv_1D(float*, float*, float*, int, int)
  0.00      1.56     0.00        1     0.00     0.00  __sti____cudaRegisterAll()
  0.00      1.56     0.00        1     0.00     0.00  cudaPrintfDisplay
  0.00      1.56     0.00        1     0.00     0.00  cudaPrintfEnd
  0.00      1.56     0.00        1     0.00     0.00  cudaPrintfInit

 %         the percentage of the total running time of the
time       program used by this function.

cumulative a running sum of the number of seconds accounted
 seconds   for by this function and those listed above it.

 self      the number of seconds accounted for by this
seconds    function alone.  This is the major sort for this
           listing.

calls      the number of times this function was invoked, if
           this function is profiled, else blank.

 self      the average number of milliseconds spent in this
ms/call    function per call, if this function is profiled,
	   else blank.

 total     the average number of milliseconds spent in this
ms/call    function and its descendents per call, if this
	   function is profiled, else blank.

name       the name of the function.  This is the minor sort
           for this listing. The index shows the location of
	   the function in the gprof listing. If the index is
	   in parenthesis it shows where it would appear in
	   the gprof listing if it were to be printed.

Copyright (C) 2012-2016 Free Software Foundation, Inc.

Copying and distribution of this file, with or without modification,
are permitted in any medium without royalty provided the copyright
notice and this notice are preserved.

		     Call graph (explanation follows)


granularity: each sample hit covers 2 byte(s) for 0.64% of 1.56 seconds

index % time    self  children    called     name
                                                 <spontaneous>
[1]    100.0    0.00    1.56                 main [1]
                1.56    0.00       1/1           wakeup_delay() [2]
                0.00    0.00      11/11          gpuAssert(cudaError, char*, int, bool) [378]
                0.00    0.00       1/1           conv_1D(float*, float*, float*, int, int) [381]
                0.00    0.00       1/23          interval(timespec, timespec) [377]
                0.00    0.00       1/1           cudaPrintfInit [5]
                0.00    0.00       1/1           cuda_conv_1D_tiled_and_shared_memory_kernel2(float*, float*, int, int) [379]
                0.00    0.00       1/1           cudaPrintfEnd [4]
                0.00    0.00       1/1           cudaPrintfDisplay [3]
-----------------------------------------------
                1.56    0.00       1/1           main [1]
[2]    100.0    1.56    0.00       1         wakeup_delay() [2]
                0.00    0.00      22/23          interval(timespec, timespec) [377]
-----------------------------------------------
                0.00    0.00       1/1           main [1]
[3]      0.0    0.00    0.00       1         cudaPrintfDisplay [3]
-----------------------------------------------
                0.00    0.00       1/1           main [1]
[4]      0.0    0.00    0.00       1         cudaPrintfEnd [4]
-----------------------------------------------
                0.00    0.00       1/1           main [1]
[5]      0.0    0.00    0.00       1         cudaPrintfInit [5]
-----------------------------------------------
                0.00    0.00       1/23          main [1]
                0.00    0.00      22/23          wakeup_delay() [2]
[377]    0.0    0.00    0.00      23         interval(timespec, timespec) [377]
-----------------------------------------------
                0.00    0.00      11/11          main [1]
[378]    0.0    0.00    0.00      11         gpuAssert(cudaError, char*, int, bool) [378]
-----------------------------------------------
                0.00    0.00       1/1           main [1]
[379]    0.0    0.00    0.00       1         cuda_conv_1D_tiled_and_shared_memory_kernel2(float*, float*, int, int) [379]
                0.00    0.00       1/1           __device_stub__Z44cuda_conv_1D_tiled_and_shared_memory_kernel2PfS_ii(float*, float*, int, int) [380]
-----------------------------------------------
                0.00    0.00       1/1           cuda_conv_1D_tiled_and_shared_memory_kernel2(float*, float*, int, int) [379]
[380]    0.0    0.00    0.00       1         __device_stub__Z44cuda_conv_1D_tiled_and_shared_memory_kernel2PfS_ii(float*, float*, int, int) [380]
-----------------------------------------------
                0.00    0.00       1/1           main [1]
[381]    0.0    0.00    0.00       1         conv_1D(float*, float*, float*, int, int) [381]
-----------------------------------------------
                0.00    0.00       1/1           __libc_csu_init [1563]
[382]    0.0    0.00    0.00       1         __sti____cudaRegisterAll() [382]
-----------------------------------------------

 This table describes the call tree of the program, and was sorted by
 the total amount of time spent in each function and its children.

 Each entry in this table consists of several lines.  The line with the
 index number at the left hand margin lists the current function.
 The lines above it list the functions that called this function,
 and the lines below it list the functions this one called.
 This line lists:
     index	A unique number given to each element of the table.
		Index numbers are sorted numerically.
		The index number is printed next to every function name so
		it is easier to look up where the function is in the table.

     % time	This is the percentage of the `total' time that was spent
		in this function and its children.  Note that due to
		different viewpoints, functions excluded by options, etc,
		these numbers will NOT add up to 100%.

     self	This is the total amount of time spent in this function.

     children	This is the total amount of time propagated into this
		function by its children.

     called	This is the number of times the function was called.
		If the function called itself recursively, the number
		only includes non-recursive calls, and is followed by
		a `+' and the number of recursive calls.

     name	The name of the current function.  The index number is
		printed after it.  If the function is a member of a
		cycle, the cycle number is printed between the
		function's name and the index number.


 For the function's parents, the fields have the following meanings:

     self	This is the amount of time that was propagated directly
		from the function into this parent.

     children	This is the amount of time that was propagated from
		the function's children into this parent.

     called	This is the number of times this parent called the
		function `/' the total number of times the function
		was called.  Recursive calls to the function are not
		included in the number after the `/'.

     name	This is the name of the parent.  The parent's index
		number is printed after it.  If the parent is a
		member of a cycle, the cycle number is printed between
		the name and the index number.

 If the parents of the function cannot be determined, the word
 `<spontaneous>' is printed in the `name' field, and all the other
 fields are blank.

 For the function's children, the fields have the following meanings:

     self	This is the amount of time that was propagated directly
		from the child into the function.

     children	This is the amount of time that was propagated from the
		child's children to the function.

     called	This is the number of times the function called
		this child `/' the total number of times the child
		was called.  Recursive calls by the child are not
		listed in the number after the `/'.

     name	This is the name of the child.  The child's index
		number is printed after it.  If the child is a
		member of a cycle, the cycle number is printed
		between the name and the index number.

 If there are any cycles (circles) in the call graph, there is an
 entry for the cycle-as-a-whole.  This entry shows who called the
 cycle (as parents) and the members of the cycle (as children.)
 The `+' recursive calls entry shows the number of function calls that
 were internal to the cycle, and the calls entry for each member shows,
 for that member, how many times it was called from other members of
 the cycle.

Copyright (C) 2012-2016 Free Software Foundation, Inc.

Copying and distribution of this file, with or without modification,
are permitted in any medium without royalty provided the copyright
notice and this notice are preserved.

Index by function name

   [2] wakeup_delay()        [377] interval(timespec, timespec) [4] cudaPrintfEnd
 [379] cuda_conv_1D_tiled_and_shared_memory_kernel2(float*, float*, int, int) [378] gpuAssert(cudaError, char*, int, bool) [5] cudaPrintfInit
 [380] __device_stub__Z44cuda_conv_1D_tiled_and_shared_memory_kernel2PfS_ii(float*, float*, int, int) [382] __sti____cudaRegisterAll() (tmpxft_0002ff2c_00000000-6_test_1d_conv.cudafe1.stub.c)
 [381] conv_1D(float*, float*, float*, int, int) [3] cudaPrintfDisplay


Size of HALO_CELL: 1
Length of input array(N): 1024
Length of mask array(M): 3
Length of output array(P): 1024

Initializing the input arrays, h_input...
h_input[1020] = 17.00
h_input[1021] = 54.00
h_input[1022] = 73.00
h_input[1023] = 0.00
Checking Intialized value for h_mask
h_mask[0] = 5.00
h_mask[1] = 6.00
h_mask[2] = 1.00
	... done

Warmup tests 

Wakeup delay computed: 1.00571 
Running code in CPU 
Finished running 1D conv in CPU 
All times are in cycles (if CPNS is set correctly in code)

N_lenth, Mask_length, output_length, 1D conv time(msec)
   1024, 	           3, 	         1024, 	    0.0961727
==========> All CPU tests are done! Now, running GPU code!
==============>Running taskid #: 6 on GPU!
1(1D single block) --> 2(1D multi-block) --> 3(1D mulit-block with mask in constant memory) --> 4(tiled algo with Strategy 1) --> 5(1D tiled strategy 1) --> 6(1D tiled strategy 2)

GPU time: 0.624544 (msec)
ZERO RESULT in 0:	0.0000	0.0000	-nan %
ZERO RESULT in 1023:	0.0000	0.0000	-nan %

@ERROR: TEST FAILED: 2/1024 results (from GPU) are zero

i:	h_output_gold[i]	h_output_data[i]
0:	0.0000	0.0000
1:	584.0000	584.0000
2:	1008.0000	1008.0000
3:	907.0000	907.0000
4:	568.0000	568.0000
5:	668.0000	668.0000
6:	761.0000	761.0000
7:	783.0000	783.0000
8:	1031.0000	1031.0000
9:	775.0000	775.0000
10:	433.0000	433.0000
11:	504.0000	504.0000
12:	562.0000	562.0000
13:	734.0000	734.0000
14:	867.0000	867.0000
15:	699.0000	699.0000
16:	511.0000	511.0000
17:	396.0000	396.0000
18:	428.0000	428.0000
19:	598.0000	598.0000
20:	587.0000	587.0000
21:	314.0000	314.0000
22:	530.0000	530.0000
23:	771.0000	771.0000
24:	591.0000	591.0000
25:	667.0000	667.0000
26:	652.0000	652.0000
27:	545.0000	545.0000
28:	515.0000	515.0000
29:	552.0000	552.0000
30:	574.0000	574.0000
31:	351.0000	351.0000
32:	179.0000	179.0000
33:	200.0000	200.0000
34:	527.0000	527.0000
35:	771.0000	771.0000
36:	840.0000	840.0000
37:	949.0000	949.0000
38:	812.0000	812.0000
39:	388.0000	388.0000
40:	336.0000	336.0000
41:	457.0000	457.0000
42:	604.0000	604.0000
43:	510.0000	510.0000
44:	303.0000	303.0000
45:	636.0000	636.0000
46:	740.0000	740.0000
47:	797.0000	797.0000
48:	649.0000	649.0000
49:	280.0000	280.0000
